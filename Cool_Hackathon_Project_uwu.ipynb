{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JameTran/cyber-crossology/blob/main/Cool_Hackathon_Project_uwu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUymE2l9GZfO"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "JMyTNwSJGGWg"
      },
      "outputs": [],
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOTzp8O36CyQ"
      },
      "source": [
        "## Setup\n",
        "\n",
        "This section sets up the environment for access to the Universal Sentence Encoder on TF Hub and provides examples of applying the encoder to words, sentences, and paragraphs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVjNK8shFKOC"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip3 install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwty8Z6mAkdV"
      },
      "outputs": [],
      "source": [
        "#@title Load the Universal Sentence Encoder's TF Hub module\n",
        "from absl import logging\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "from google.colab import files\n",
        "import random as rand\n",
        "\n",
        "\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"]\n",
        "model = hub.load(module_url)\n",
        "print (\"module %s loaded\" % module_url)\n",
        "def embed(input):\n",
        "  return model(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnvjATdy64eR"
      },
      "source": [
        "# Semantic Textual Similarity Task Example\n",
        "\n",
        "The embeddings produced by the Universal Sentence Encoder are approximately normalized. The semantic similarity of two sentences can be trivially computed as the inner product of the encodings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1FFCTKm7ba4"
      },
      "outputs": [],
      "source": [
        "def plot_similarity(labels, features, rotation):\n",
        "  corr = np.inner(features, features)\n",
        "  sns.set(font_scale=1.2)\n",
        "  g = sns.heatmap(\n",
        "      corr,\n",
        "      xticklabels=labels,\n",
        "      yticklabels=labels,\n",
        "      vmin=0,\n",
        "      vmax=1,\n",
        "      cmap=\"YlOrRd\")\n",
        "  g.set_xticklabels(labels, rotation=rotation)\n",
        "  g.set_title(\"Semantic Textual Similarity\")\n",
        "\n",
        "def run_and_plot(messages_):\n",
        "  message_embeddings_ = embed(messages_)\n",
        "  plot_similarity(messages_, message_embeddings_, 90)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def semantic_similarity(v1, v2):\n",
        "  embed_v1 = embed(v1)\n",
        "  embed_v2 = embed(v2)\n",
        "  return np.inner(embed_v1, embed_v2)[0][0]\n",
        "\n",
        "#method to determine if two sentences have a semantic similarity above a given target value\n",
        "# @ target is a value between 0 and 1, with higher values being more semantically similar\n",
        "def is_similar(v1, v2, target):\n",
        "  if semantic_similarity(v1, v2) > target:\n",
        "    return True\n",
        "  else:\n",
        "      return False\n",
        "\n",
        "a = [\"quick\"]\n",
        "b = [\"fast\"]\n",
        "\n",
        "print(semantic_similarity(a, b)) \n",
        "print(is_similar(a, b, 0.1))\n",
        "\n"
      ],
      "metadata": {
        "id": "sK6gH3F7wmcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REMEMBER TO UPLOAD THE FILE FROM LOCAL MACHINE** \n",
        "\n",
        "Code to open the word bank text file, and creating a new list with no apostrophes and spaces (for the crossword generation)"
      ],
      "metadata": {
        "id": "UtF3qFxFY4xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('the_words_singular.txt') as f:\n",
        "    lines = f.read().splitlines()\n",
        "nospaces = []\n",
        "for i in lines:\n",
        "  a = i.replace(' ', '')\n",
        "  a = a.replace(\"'\", '')\n",
        "  nospaces.append(a)\n"
      ],
      "metadata": {
        "id": "JcVmKJMdUent"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "User Input Section. Takes in the user's 'starter' words, as well as the number of words they want in their crossword"
      ],
      "metadata": {
        "id": "xKvulDJwaLJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "usr_input = []\n",
        "while True:\n",
        "  a = str(input(\"Please enter the starter words for your crossword! To quit, type 'q' \"))\n",
        "  if a == 'q':\n",
        "    break\n",
        "  usr_input.append(a)\n",
        "\n",
        "cw_number = int(input(\"How many words would you like in your crossword?: \"))\n"
      ],
      "metadata": {
        "id": "x3L_bfwfaF7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Long ass computation so we put it in another cell"
      ],
      "metadata": {
        "id": "7jb2WMxQH4_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Computes all the semantic similarities, stores them in a dict so we don't need to calculate them again\n",
        "# I know this is awful I am so sorry T_T\n",
        "embed_scores = []\n",
        "for i in usr_input:\n",
        "  a = [i]\n",
        "  temp = {}\n",
        "  for j in lines:\n",
        "    b = [j]\n",
        "    temp[j] = semantic_similarity(a, b)\n",
        "    print(\"uwu\")\n",
        "\n",
        "  embed_scores.append(temp)\n",
        "  \n",
        "print(embed_scores[0])"
      ],
      "metadata": {
        "id": "ABhCc-uTHxR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Take number of words in crossword, divide by length of input to find how many similar words allocated to each starter word\n",
        "len_input = len(usr_input)\n",
        "\n",
        "number_allocated = []  #List to hold the number of similar words allocated to each input\n",
        "base_num = int(cw_number/len_input)#Determines the base number of words allocated\n",
        "remainder = cw_number % len_input \n",
        "\n",
        "#Determines how many numbers are left over. and distributes them amongst the first n elements until no more remainder is left\n",
        "for i in range(len_input):\n",
        "  if remainder != 0:\n",
        "    number_allocated.append(base_num + 1)\n",
        "    remainder-=1\n",
        "  else:\n",
        "    number_allocated.append(base_num)\n",
        "print(number_allocated)\n"
      ],
      "metadata": {
        "id": "Dy1LGuJvbdpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Iterates through dictionary to find most similar values\n",
        "# testing for 3 values\n",
        "\n",
        "count = 0\n",
        "temp = []\n",
        "for key, value in embed_scores[0].items():\n",
        "  if count > 50:\n",
        "    break\n",
        "  if value > 0.58:\n",
        "    temp2 = []\n",
        "    for i in embed_scores:\n",
        "      temp2.append(i.get(key))\n",
        "    if all(j >= 0.3 for j in temp2) == True:\n",
        "      a = [key, value]\n",
        "      temp.append(a)\n",
        "      count+=1\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "\n",
        "print(temp)\n",
        "print(len(temp))\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "xCiX7BjzIbeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Grab 25 numbers, order them from highest score\n",
        "top_embeds = []\n",
        "def Sort_sub_list(sub_li):\n",
        "  \n",
        "    # reverse = None (Sorts in Ascending order)\n",
        "    # key is set to sort using second element of \n",
        "    # sublist lambda has been used\n",
        "    return(sorted(sub_li, key = lambda x: x[1], reverse=True))\n",
        "\n",
        "top_embeds = Sort_sub_list(temp)\n",
        "top_embeds_25 = top_embeds[:26]\n",
        "print(top_embeds_25)"
      ],
      "metadata": {
        "id": "U2EbKBE6qZA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0WOXou9AFwBW"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "RUymE2l9GZfO"
      ],
      "name": "Cool Hackathon Project uwu",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}